defaults:
  - _self_
  - model: roberta-large
  - method: swag

experiment:
  seed: 10
  use_loraxs: True # whether to use LoRa-XS or LoRa modules

  val_split_size: 0.2
  gradient_accumulation_steps: 1

  task: "mrpc"
  subtask: ''
  ood_task: "" # leave empty for no OOD evaluation
  ood_subtask: ""
  ood_batch_size: 16
  learning_rate: 1e-3
  cls_learning_rate: 1e-3 # classifier learning rate
  batch_size: 32
  num_epochs: 15
  set_fraction: 1.0 # fraction of training dataset used for learning (value between 0 and 1, inclusively)

  weight_decay: 0
  scheduler: 'linear'
  warmup_length: 0.06
  num_lr_cycles: 0.5
  eval_upon_save: True

  # wandb parameters
  wandb_entity: "default"
  wandb_project: "project"
  wandb_group: "default"
  wandb_mode: "online"

  # lora hyperparams
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.0
  train_biases: 'none'

  save_folder: './need_folder_specification' # default save location
  save_path: './should_not_be_saving_here' # will get replaced
  exp_name: '' # will get replaced unless it is set by the user

  overwrite: False
  data_path: './need_folder_specification'      # /path/to/your/data
  model_path: './need_folder_specification'     # /path/to/your/models (for offline loading)
  wandb_path: './need_folder_specification' # /path/to/wandb

  mnli_model_path: './model_checkpoints/MNLI/rank_8' # path to pretrained LoRa-XS weights for given rank on MNLI task
  # used only for RTE and MRPC tasks
  offline: False

evaluation:
  seed: 10
  eval_method: 'swag' # 'swag' | 'dropout'
  eval_model_path: 'NONE' # set to the model path to use in evaluation
  num_samples: 1 # number of samples (e.g. for dropout/SWAG)
  swag_sample_scale: 1.0 # covariance scaling parameter for SWAG (https://github.com/wjmaddox/swa_gaussian)
  only_ood: False # only run OOD eval (skip ID eval)

hydra:
  run:
    dir: "test" # hydra output dir